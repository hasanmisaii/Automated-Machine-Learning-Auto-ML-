{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning for Regression Tasks\n",
    "\n",
    "This notebook demonstrates how to use Azure Automated Machine Learning (AutoML) for regression tasks. We'll create a complete end-to-end example that includes:\n",
    "\n",
    "* Data preparation and exploration\n",
    "* Setting up Azure ML workspace\n",
    "* Configuring AutoML for regression\n",
    "* Training and evaluating models\n",
    "* Analyzing regression-specific metrics\n",
    "* Model interpretation and insights\n",
    "\n",
    "## What is Regression?\n",
    "Regression is a machine learning task that predicts continuous numerical values. Common examples include:\n",
    "- Predicting house prices\n",
    "- Forecasting sales revenue\n",
    "- Estimating energy consumption\n",
    "- Calculating insurance premiums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Please ensure you have the following installed:\n",
    "- Azure Machine Learning Python SDK v2\n",
    "- Required data science libraries\n",
    "\n",
    "```bash\n",
    "pip install azure-ai-ml azure-identity\n",
    "pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Exploration\n",
    "\n",
    "For this demo, we'll create a synthetic regression dataset that simulates real-world scenarios. This approach ensures the notebook works without external dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic regression dataset\n",
    "# This simulates a house price prediction scenario\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate base features\n",
    "X, y = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    noise=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create meaningful feature names for house price prediction\n",
    "feature_names = [\n",
    "    'square_footage', 'bedrooms', 'bathrooms', 'age', 'lot_size',\n",
    "    'garage_size', 'neighborhood_score', 'school_rating', 'distance_to_city', 'crime_rate'\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Scale features to realistic ranges\n",
    "df['square_footage'] = ((df['square_footage'] - df['square_footage'].min()) / \n",
    "                       (df['square_footage'].max() - df['square_footage'].min()) * 2000 + 800).round(0)\n",
    "df['bedrooms'] = ((df['bedrooms'] - df['bedrooms'].min()) / \n",
    "                 (df['bedrooms'].max() - df['bedrooms'].min()) * 4 + 1).round(0)\n",
    "df['bathrooms'] = ((df['bathrooms'] - df['bathrooms'].min()) / \n",
    "                  (df['bathrooms'].max() - df['bathrooms'].min()) * 3 + 1).round(1)\n",
    "df['age'] = ((df['age'] - df['age'].min()) / \n",
    "            (df['age'].max() - df['age'].min()) * 50).round(0)\n",
    "df['lot_size'] = ((df['lot_size'] - df['lot_size'].min()) / \n",
    "                 (df['lot_size'].max() - df['lot_size'].min()) * 1 + 0.1).round(2)\n",
    "\n",
    "# Scale target to realistic house prices (in thousands)\n",
    "y_scaled = ((y - y.min()) / (y.max() - y.min()) * 400 + 150).round(1)\n",
    "df['price'] = y_scaled\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Target variable (price) range: ${df['price'].min():.1f}k - ${df['price'].max():.1f}k\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration and visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribution of target variable\n",
    "axes[0, 0].hist(df['price'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Distribution of House Prices')\n",
    "axes[0, 0].set_xlabel('Price (thousands $)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Correlation heatmap\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            ax=axes[0, 1], fmt='.2f')\n",
    "axes[0, 1].set_title('Feature Correlation Matrix')\n",
    "\n",
    "# Scatter plot: Square footage vs Price\n",
    "axes[1, 0].scatter(df['square_footage'], df['price'], alpha=0.6, color='coral')\n",
    "axes[1, 0].set_xlabel('Square Footage')\n",
    "axes[1, 0].set_ylabel('Price (thousands $)')\n",
    "axes[1, 0].set_title('Square Footage vs Price')\n",
    "\n",
    "# Feature importance (correlation with target)\n",
    "feature_corr = df.corr()['price'].drop('price').sort_values(key=abs, ascending=False)\n",
    "axes[1, 1].barh(range(len(feature_corr)), feature_corr.values, color='lightgreen')\n",
    "axes[1, 1].set_yticks(range(len(feature_corr)))\n",
    "axes[1, 1].set_yticklabels(feature_corr.index)\n",
    "axes[1, 1].set_xlabel('Correlation with Price')\n",
    "axes[1, 1].set_title('Feature Correlation with Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nDataset Summary Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "Initialize connection to your Azure ML workspace. Update the subscription, resource group, and workspace name according to your Azure setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Azure ML workspace configuration\n",
    "# Update these values with your Azure subscription details\n",
    "subscription_id = \"your-subscription-id\"\n",
    "resource_group = \"your-resource-group\"\n",
    "workspace_name = \"your-workspace-name\"\n",
    "\n",
    "# Authenticate and create ML client\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)\n",
    "    workspace = ml_client.workspaces.get(name=ml_client.workspace_name)\n",
    "    print(f\"Connected to workspace: {ml_client.workspace_name}\")\n",
    "    print(f\"Resource group: {workspace.resource_group}\")\n",
    "    print(f\"Location: {workspace.location}\")\n",
    "    print(f\"Subscription: {ml_client.connections._subscription_id}\")\nexcept Exception as e:\n",
    "    print(f\"Authentication failed: {e}\")\n",
    "    print(\"Please ensure you're logged in to Azure CLI or have proper credentials configured\")\n",
    "    print(\"You can continue with the local demonstration without Azure ML connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for AutoML\n",
    "\n",
    "Split the data and save it in a format that Azure AutoML can consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create training dataset\n",
    "train_data = X_train.copy()\n",
    "train_data['price'] = y_train\n",
    "\n",
    "# Create test dataset for evaluation\n",
    "test_data = X_test.copy()\n",
    "test_data['price'] = y_test\n",
    "\n",
    "print(f\"Training set shape: {train_data.shape}\")\n",
    "print(f\"Test set shape: {test_data.shape}\")\n",
    "\n",
    "# Save datasets locally\n",
    "import os\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "train_data.to_csv('./data/train_regression_data.csv', index=False)\n",
    "test_data.to_csv('./data/test_regression_data.csv', index=False)\n",
    "\n",
    "print(\"\\nDatasets saved locally in ./data/ directory\")\n",
    "print(\"Files created:\")\n",
    "print(\"- train_regression_data.csv\")\n",
    "print(\"- test_regression_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Azure AutoML for Regression\n",
    "\n",
    "Set up AutoML configuration specifically for regression tasks. This includes specifying the target column, task type, and optimization metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import automl\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# Create data input for AutoML\n",
    "# In a real scenario, you would upload this to Azure ML datastore\n",
    "training_data_input = Input(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"./data/train_regression_data.csv\"\n",
    ")\n",
    "\n",
    "# Configure AutoML job for regression\n",
    "regression_job = automl.regression(\n",
    "    # Data configuration\n",
    "    training_data=training_data_input,\n",
    "    target_column_name=\"price\",\n",
    "    \n",
    "    # Primary metric for optimization\n",
    "    primary_metric=\"normalized_root_mean_squared_error\",\n",
    "    \n",
    "    # Experiment settings\n",
    "    experiment_name=\"house-price-regression-automl\",\n",
    "    \n",
    "    # Model training settings\n",
    "    enable_model_explainability=True,\n",
    "    enable_early_stopping=True,\n",
    "    \n",
    "    # Timeout and trial settings\n",
    "    experiment_timeout_hours=0.5,  # 30 minutes for demo\n",
    "    max_trials=10,\n",
    "    max_concurrent_trials=2,\n",
    "    \n",
    "    # Cross-validation\n",
    "    n_cross_validations=3,\n",
    "    \n",
    "    # Feature engineering\n",
    "    enable_feature_engineering=True,\n",
    "    \n",
    "    # Tags for organization\n",
    "    tags={\"task\": \"regression\", \"dataset\": \"synthetic_house_prices\"}\n",
    ")\n",
    "\n",
    "print(\"AutoML regression job configured successfully!\")\n",
    "print(f\"Target column: {regression_job.target_column_name}\")\n",
    "print(f\"Primary metric: {regression_job.primary_metric}\")\n",
    "print(f\"Max trials: {regression_job.limits.max_trials}\")\n",
    "print(f\"Experiment timeout: {regression_job.limits.timeout_minutes} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up Compute Target\n",
    "\n",
    "Create or use existing compute target for running the AutoML experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Define compute cluster name\n",
    "cluster_name = \"regression-compute\"\n",
    "\n",
    "try:\n",
    "    # Check if compute target already exists\n",
    "    compute_target = ml_client.compute.get(cluster_name)\n",
    "    print(f\"Found existing compute target: {cluster_name}\")\n",
    "    print(f\"VM size: {compute_target.size}\")\n",
    "    print(f\"Max instances: {compute_target.max_instances}\")\n",
    "    \nexcept Exception:\n",
    "    print(f\"Creating new compute target: {cluster_name}\")\n",
    "    \n",
    "    # Create new compute target\n",
    "    compute_config = AmlCompute(\n",
    "        name=cluster_name,\n",
    "        size=\"Standard_DS3_v2\",  # Good for AutoML workloads\n",
    "        max_instances=4,\n",
    "        min_instances=0,\n",
    "        idle_time_before_scale_down=120,  # Scale down after 2 minutes\n",
    "        tier=\"Dedicated\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        compute_target = ml_client.compute.begin_create_or_update(compute_config)\n",
    "        print(\"Compute target creation initiated...\")\n",
    "        print(\"This may take a few minutes to complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create compute target: {e}\")\n",
    "        print(\"You can run this experiment on any available compute target\")\n",
    "\n",
    "# Set compute target for the job\n",
    "if 'ml_client' in locals():\n",
    "    regression_job.compute = cluster_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Submit AutoML Experiment\n",
    "\n",
    "Submit the regression experiment to Azure AutoML. This will train multiple models and select the best one based on the specified metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the AutoML job\n",
    "if 'ml_client' in locals():\n",
    "    try:\n",
    "        returned_job = ml_client.jobs.create_or_update(regression_job)\n",
    "        \n",
    "        print(f\"AutoML job submitted successfully!\")\n",
    "        print(f\"Job name: {returned_job.name}\")\n",
    "        print(f\"Job status: {returned_job.status}\")\n",
    "        print(f\"Studio URL: {returned_job.studio_url}\")\n",
    "        \n",
    "        # You can monitor the job in Azure ML Studio using the URL above\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"IMPORTANT: Monitor your job progress at:\")\n",
    "        print(returned_job.studio_url)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to submit job: {e}\")\n",
    "        print(\"Please check your Azure ML configuration and permissions\")\nelse:\n",
    "    print(\"Azure ML client not configured. Skipping job submission.\")\n",
    "    print(\"To run this experiment, please configure your Azure ML workspace credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Local Regression Model Demonstration\n",
    "\n",
    "While the Azure AutoML job runs, let's demonstrate regression concepts with a local model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train a simple local model for demonstration\n",
    "print(\"Training local regression models for comparison...\")\n",
    "\n",
    "# Scale features for linear regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train multiple models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Linear Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"  RMSE: ${rmse:.2f}k\")\n",
    "    print(f\"  MAE:  ${mae:.2f}k\")\n",
    "    print(f\"  R²:   {r2:.3f}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'RMSE': [results[model]['RMSE'] for model in results.keys()],\n",
    "    'MAE': [results[model]['MAE'] for model in results.keys()],\n",
    "    'R²': [results[model]['R²'] for model in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regression Metrics Visualization\n",
    "\n",
    "Visualize model performance with regression-specific plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive regression visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Model comparison bar chart\n",
    "x_pos = np.arange(len(results_df))\n",
    "axes[0, 0].bar(x_pos, results_df['RMSE'], color=['skyblue', 'lightcoral'])\n",
    "axes[0, 0].set_xlabel('Models')\n",
    "axes[0, 0].set_ylabel('RMSE (thousands $)')\n",
    "axes[0, 0].set_title('Model Comparison - RMSE')\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(results_df['Model'])\n",
    "\n",
    "# R² comparison\n",
    "axes[0, 1].bar(x_pos, results_df['R²'], color=['lightgreen', 'orange'])\n",
    "axes[0, 1].set_xlabel('Models')\n",
    "axes[0, 1].set_ylabel('R² Score')\n",
    "axes[0, 1].set_title('Model Comparison - R² Score')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels(results_df['Model'])\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# Predicted vs Actual scatter plot (Random Forest)\n",
    "rf_predictions = results['Random Forest']['predictions']\n",
    "axes[0, 2].scatter(y_test, rf_predictions, alpha=0.6, color='purple')\n",
    "axes[0, 2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 2].set_xlabel('Actual Price (thousands $)')\n",
    "axes[0, 2].set_ylabel('Predicted Price (thousands $)')\n",
    "axes[0, 2].set_title('Random Forest: Predicted vs Actual')\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - rf_predictions\n",
    "axes[1, 0].scatter(rf_predictions, residuals, alpha=0.6, color='red')\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='--')\n",
    "axes[1, 0].set_xlabel('Predicted Price (thousands $)')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Residuals Plot (Random Forest)')\n",
    "\n",
    "# Distribution of residuals\n",
    "axes[1, 1].hist(residuals, bins=20, alpha=0.7, color='cyan')\n",
    "axes[1, 1].set_xlabel('Residuals')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Residuals')\n",
    "\n",
    "# Feature importance (Random Forest)\n",
    "if hasattr(models['Random Forest'], 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': models['Random Forest'].feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    axes[1, 2].barh(range(len(feature_importance)), feature_importance['importance'], color='gold')\n",
    "    axes[1, 2].set_yticks(range(len(feature_importance)))\n",
    "    axes[1, 2].set_yticklabels(feature_importance['feature'])\n",
    "    axes[1, 2].set_xlabel('Feature Importance')\n",
    "    axes[1, 2].set_title('Random Forest Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key insights\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY REGRESSION INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best performing model: {results_df.loc[results_df['R²'].idxmax(), 'Model']}\")\n",
    "print(f\"Highest R² score: {results_df['R²'].max():.3f}\")\n",
    "print(f\"Lowest RMSE: ${results_df['RMSE'].min():.2f}k\")\nprint(f\"\\nMost important features (Random Forest):\")\nif 'feature_importance' in locals():\n    top_features = feature_importance.tail(3)\n    for _, row in top_features.iterrows():\n        print(f\"  {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Understanding Regression Metrics\n",
    "\n",
    "Let's understand what each regression metric tells us about model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"REGRESSION METRICS EXPLAINED\")\nprint(\"=\" * 40)\nprint()\nprint(\"📊 R² (R-squared): Coefficient of Determination\")\nprint(\"   • Range: 0 to 1 (higher is better)\")\nprint(\"   • Measures how much variance in target is explained by features\")\nprint(f\"   • Our best model explains {results_df['R²'].max()*100:.1f}% of price variance\")\nprint()\nprint(\"📏 RMSE (Root Mean Squared Error):\")\nprint(\"   • Units: Same as target variable (thousands $)\")\nprint(\"   • Penalizes large errors more heavily\")\nprint(f\"   • Our best model has average error of ${results_df['RMSE'].min():.1f}k\")\nprint()\nprint(\"📐 MAE (Mean Absolute Error):\")\nprint(\"   • Units: Same as target variable (thousands $)\")\nprint(\"   • Average absolute difference between predicted and actual\")\nprint(f\"   • Our best model has median error of ${results_df['MAE'].min():.1f}k\")\nprint()\nprint(\"🎯 Business Impact:\")\nprint(f\"   • Price range: ${df['price'].min():.0f}k - ${df['price'].max():.0f}k\")\nprint(f\"   • Average price: ${df['price'].mean():.0f}k\")\nprint(f\"   • Model error as % of average price: {(results_df['RMSE'].min()/df['price'].mean())*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. AutoML Results Analysis (if connected to Azure)\n",
    "\n",
    "If you submitted the AutoML job, you can retrieve and analyze the results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check AutoML job status and retrieve results\n",
    "if 'ml_client' in locals() and 'returned_job' in locals():\n",
    "    try:\n",
    "        # Get job details\n",
    "        job_details = ml_client.jobs.get(returned_job.name)\n",
    "        print(f\"Job Status: {job_details.status}\")\n",
    "        print(f\"Job Name: {job_details.name}\")\n",
    "        \n",
    "        if job_details.status == \"Completed\":\n",
    "            print(\"\\n🎉 AutoML job completed successfully!\")\n",
    "            \n",
    "            # You can retrieve the best model and its metrics here\n",
    "            # This would require additional code to download and analyze the model\n",
    "            print(\"\\nTo analyze the AutoML results:\")\n",
    "            print(\"1. Visit the Studio URL provided earlier\")\n",
    "            print(\"2. Review the model leaderboard\")\n",
    "            print(\"3. Examine feature importance and explanations\")\n",
    "            print(\"4. Download the best model for deployment\")\n",
    "            \n",
    "        elif job_details.status == \"Running\":\n",
    "            print(\"\\n⏳ AutoML job is still running...\")\n",
    "            print(\"You can monitor progress in Azure ML Studio\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n⚠️ Job status: {job_details.status}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving job status: {e}\")\nelse:\n",
    "    print(\"AutoML job was not submitted. To run AutoML:\")\n    print(\"1. Configure Azure ML workspace credentials\")\n    print(\"2. Re-run the AutoML submission cells\")\n    print(\"3. Monitor progress in Azure ML Studio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps and Best Practices\n",
    "\n",
    "This notebook demonstrated the fundamentals of regression with AutoML. Here are recommended next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 NEXT STEPS FOR PRODUCTION REGRESSION MODELS\")\nprint(\"=\" * 55)\nprint()\nprint(\"📊 Data Quality:\")\nprint(\"   • Handle missing values appropriately\")\nprint(\"   • Remove or transform outliers\")\nprint(\"   • Ensure feature distributions are reasonable\")\nprint(\"   • Check for data leakage\")\nprint()\nprint(\"🔧 Feature Engineering:\")\nprint(\"   • Create polynomial features for non-linear relationships\")\nprint(\"   • Apply domain-specific transformations\")\nprint(\"   • Use feature selection techniques\")\nprint(\"   • Handle categorical variables properly\")\nprint()\nprint(\"🎯 Model Selection:\")\nprint(\"   • Try ensemble methods (Random Forest, Gradient Boosting)\")\nprint(\"   • Consider neural networks for complex patterns\")\nprint(\"   • Use cross-validation for robust evaluation\")\nprint(\"   • Compare multiple metrics, not just one\")\nprint()\nprint(\"📈 Model Validation:\")\nprint(\"   • Use time-based splits for time series data\")\nprint(\"   • Validate on out-of-sample data\")\nprint(\"   • Check residual patterns\")\nprint(\"   • Test model stability over time\")\nprint()\nprint(\"🚀 Deployment:\")\nprint(\"   • Set up model monitoring\")\nprint(\"   • Plan for model retraining\")\nprint(\"   • Implement A/B testing\")\nprint(\"   • Document model limitations and assumptions\")\nprint()\nprint(\"💡 AutoML Benefits:\")\nprint(\"   • Automatically tries multiple algorithms\")\nprint(\"   • Handles feature engineering\")\nprint(\"   • Provides model explanations\")\nprint(\"   • Optimizes hyperparameters\")\nprint(\"   • Reduces time to production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provided a comprehensive introduction to regression tasks using Automated Machine Learning. We covered:\n",
    "\n",
    "1. **Data Preparation**: Created and explored a realistic regression dataset\n",
    "2. **Azure ML Setup**: Connected to Azure ML workspace and configured compute\n",
    "3. **AutoML Configuration**: Set up AutoML specifically for regression tasks\n",
    "4. **Model Training**: Submitted AutoML job and trained local models for comparison\n",
    "5. **Evaluation**: Analyzed regression metrics (RMSE, MAE, R²) and visualizations\n",
    "6. **Insights**: Interpreted model performance and feature importance\n",
    "\n",
    "### Key Takeaways:\n",
    "- Regression predicts continuous numerical values\n",
    "- AutoML automates model selection and hyperparameter tuning\n",
    "- Multiple metrics provide different perspectives on model performance\n",
    "- Feature importance helps understand what drives predictions\n",
    "- Azure AutoML provides enterprise-grade MLOps capabilities\n",
    "\n",
    "For production use, always validate models thoroughly and consider business context when interpreting results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}